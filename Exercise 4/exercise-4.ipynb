{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:44:58.882251Z","iopub.status.busy":"2023-05-03T10:44:58.881546Z","iopub.status.idle":"2023-05-03T10:44:58.886822Z","shell.execute_reply":"2023-05-03T10:44:58.885707Z","shell.execute_reply.started":"2023-05-03T10:44:58.882212Z"},"trusted":true},"outputs":[],"source":["#%matplotlib inline"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:44:59.434107Z","iopub.status.busy":"2023-05-03T10:44:59.433201Z","iopub.status.idle":"2023-05-03T10:44:59.497177Z","shell.execute_reply":"2023-05-03T10:44:59.495787Z","shell.execute_reply.started":"2023-05-03T10:44:59.434069Z"},"trusted":true},"outputs":[],"source":["import random\n","import time\n","import math\n","import string\n","\n","from tqdm import tqdm\n","from urllib.request import urlopen\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","# Making the code device-agnostic\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","random.seed(10)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Task 1"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Import and format text"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:45:00.586544Z","iopub.status.busy":"2023-05-03T10:45:00.585863Z","iopub.status.idle":"2023-05-03T10:45:00.594267Z","shell.execute_reply":"2023-05-03T10:45:00.593183Z","shell.execute_reply.started":"2023-05-03T10:45:00.586504Z"},"trusted":true},"outputs":[],"source":["\n","all_characters = string.printable\n","n_characters = len(all_characters)\n","\n","# Reading and un-unicode-encoding data\n","def read_file(url):\n","    file = urlopen(url).read().decode()\n","    return file, len(file)\n","\n","# Turning a string into a tensor\n","def char_tensor(string):\n","    tensor = torch.zeros(len(string)).long()\n","    for c in range(len(string)):\n","        try:\n","            tensor[c] = all_characters.index(string[c])\n","        except:\n","            continue\n","    return tensor\n","\n","# Readable time elapsed\n","def time_since(since):\n","    s = time.time() - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Model creation"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:45:01.159089Z","iopub.status.busy":"2023-05-03T10:45:01.157864Z","iopub.status.idle":"2023-05-03T10:45:01.179246Z","shell.execute_reply":"2023-05-03T10:45:01.178333Z","shell.execute_reply.started":"2023-05-03T10:45:01.159042Z"},"trusted":true},"outputs":[],"source":["class CharRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, model=\"gru\", n_layers=1):\n","        super(CharRNN, self).__init__()\n","        self.model = model.lower()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","\n","        self.encoder = nn.Embedding(input_size, hidden_size)\n","        if self.model == \"gru\":\n","            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n","        elif self.model == \"lstm\":\n","            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n","        self.decoder = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, input, hidden):\n","        batch_size = input.size(0)\n","        encoded = self.encoder(input)\n","        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n","        output = self.decoder(output.view(batch_size, -1))\n","        return output, hidden\n","\n","    def forward2(self, input, hidden):\n","        encoded = self.encoder(input.view(1, -1))\n","        output, hidden = self.rnn(encoded.view(1, 1, -1), hidden)\n","        output = self.decoder(output.view(1, -1))\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        if self.model == \"lstm\":\n","            return (torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device),\n","                    torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device))\n","        return torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:45:01.624008Z","iopub.status.busy":"2023-05-03T10:45:01.623199Z","iopub.status.idle":"2023-05-03T10:45:05.512191Z","shell.execute_reply":"2023-05-03T10:45:05.511092Z","shell.execute_reply.started":"2023-05-03T10:45:01.623966Z"},"trusted":true},"outputs":[],"source":["batch_size = 100\n","learning_rate = 0.01\n","n_epochs = 2000\n","chunk_len = 200\n","\n","decoder = CharRNN(\n","    input_size=n_characters,\n","    hidden_size=50,\n","    output_size=n_characters,\n","    model=\"lstm\",    # \"gru\" or \"lstm\"\n","    n_layers=2,\n",").to(device)\n","\n","decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Tiny Shakespear dataset\n","url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","file, file_len = read_file(url)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Define functions"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:45:05.514435Z","iopub.status.busy":"2023-05-03T10:45:05.514021Z","iopub.status.idle":"2023-05-03T10:45:05.528228Z","shell.execute_reply":"2023-05-03T10:45:05.527012Z","shell.execute_reply.started":"2023-05-03T10:45:05.514398Z"},"trusted":true},"outputs":[],"source":["\n","def random_training_set(chunk_len, batch_size):\n","    inp = torch.LongTensor(batch_size, chunk_len)\n","    target = torch.LongTensor(batch_size, chunk_len)\n","    for bi in range(batch_size):\n","        start_index = random.randint(0, file_len - chunk_len)\n","        end_index = start_index + chunk_len + 1\n","        chunk = file[start_index:end_index]\n","        inp[bi] = char_tensor(chunk[:-1])\n","        target[bi] = char_tensor(chunk[1:])\n","    \n","    #Add to device\n","    inp = inp.to(device)\n","    target = target.to(device)\n","    \n","    return inp, target\n","\n","\n","def train(inp, target):\n","    hidden = decoder.init_hidden(batch_size)\n","    decoder.zero_grad()\n","    loss = 0\n","\n","    for c in range(chunk_len):\n","        output, hidden = decoder(inp[:,c], hidden)\n","        loss += criterion(output.view(batch_size, -1), target[:,c])\n","\n","    loss.backward()\n","    decoder_optimizer.step()\n","\n","    return loss.data / chunk_len    \n","\n","\n","def generate(decoder, prime_str='A', predict_len=100, temperature=0.8, device=device):\n","    hidden = decoder.init_hidden(1)\n","    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n","\n","    prime_input = prime_input.to(device)\n","    predicted = prime_str\n","\n","    # Use priming string to \"build up\" hidden state\n","    for p in range(len(prime_str) - 1):\n","        _, hidden = decoder(prime_input[:,p], hidden)\n","        \n","    inp = prime_input[:,-1]\n","    \n","    for p in range(predict_len):\n","        output, hidden = decoder(inp, hidden)\n","        \n","        # Sample from the network as a multinomial distribution\n","        output_dist = output.data.view(-1).div(temperature).exp()\n","        top_i = torch.multinomial(output_dist, 1)[0]\n","\n","        # Add predicted character to string and use as next input\n","        predicted_char = all_characters[top_i]\n","        predicted += predicted_char\n","        inp = char_tensor(predicted_char).unsqueeze(0).to(device)\n","\n","    return predicted"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Train model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for 2000 epochs...\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 100/2000 [00:42<13:40,  2.31it/s]"]},{"name":"stdout","output_type":"stream","text":["[0m 42s (100 5%) 2.3060]\n","\n","Wher orwand fom hen brorife souch arate the foeg he chast By un urscaghle lopes thee ry oll cy the id  \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 200/2000 [01:22<12:09,  2.47it/s]"]},{"name":"stdout","output_type":"stream","text":["[1m 22s (200 10%) 2.0332]\n","\n","Whe us the is that sey prakner on you thas\n","\n","Bamecfhir heor corres blord and seis dor?\n","\n","\n","\n","KENGTIRS:\n","\n","Wore,  \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▌        | 300/2000 [02:01<11:24,  2.48it/s]"]},{"name":"stdout","output_type":"stream","text":["[2m 1s (300 15%) 1.8936]\n","\n","Whas the what leort's blated.\n","\n","\n","\n","CLIRF ICHIO:\n","\n","Where thoude him me it thive opes\n","\n","I on and gould of cable  \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 400/2000 [02:39<10:52,  2.45it/s]"]},{"name":"stdout","output_type":"stream","text":["[2m 39s (400 20%) 1.7997]\n","\n","Whow we we porbiste he riderit, gat! it so died\n","\n","Op in whow, there 'ty now agale, so dosess,\n","\n","The sweedi \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 500/2000 [03:17<09:52,  2.53it/s]"]},{"name":"stdout","output_type":"stream","text":["[3m 17s (500 25%) 1.7434]\n","\n","Who prace, I wrow I brost he put on the to with live,\n","\n","And from the dalt, on Romeich for the come here\n","\n"," \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 600/2000 [03:55<09:34,  2.44it/s]"]},{"name":"stdout","output_type":"stream","text":["[3m 55s (600 30%) 1.6912]\n","\n","What this forcout be as drock a father, and grace the mencings vore; the in a unvicesfar himfort who t \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▌      | 700/2000 [04:33<09:03,  2.39it/s]"]},{"name":"stdout","output_type":"stream","text":["[4m 33s (700 35%) 1.6581]\n","\n","Whatk to have solly back;\n","\n","Iy rike that son, fit it you here outh bones the day the couch.\n","\n","To-proved wa \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 800/2000 [05:13<07:57,  2.51it/s]"]},{"name":"stdout","output_type":"stream","text":["[5m 13s (800 40%) 1.6452]\n","\n","Whis hence of I clopess: I have do grought\n","\n","Marwiling, and wison, nor brown\n","\n","And. And I the pring:\n","\n","And t \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▌     | 900/2000 [05:51<07:24,  2.48it/s]"]},{"name":"stdout","output_type":"stream","text":["[5m 51s (900 45%) 1.6221]\n","\n","Whas country her your lost of his say on mean,\n","\n","What you undate wesklards have heriens;\n","\n","Where out do th \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 1000/2000 [06:29<06:50,  2.43it/s]"]},{"name":"stdout","output_type":"stream","text":["[6m 29s (1000 50%) 1.6205]\n","\n","Whirgeral honory or the make fink\n","\n","Is shall chum is the scongue\n","\n","Lonce, foul so the tamel: daughter doul \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▌    | 1100/2000 [07:08<06:11,  2.42it/s]"]},{"name":"stdout","output_type":"stream","text":["[7m 8s (1100 55%) 1.6084]\n","\n","What compost the onest him did the brother, he? Sirn perforge at in the all to plaughtion?\n","\n","Go long of  \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 1200/2000 [07:47<05:35,  2.38it/s]"]},{"name":"stdout","output_type":"stream","text":["[7m 47s (1200 60%) 1.5940]\n","\n","Whe his deper that he brongeren: what so,\n","\n","Of win to get of my sown mine.\n","\n","\n","\n","Nurse:\n","\n","The part this truth i \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▌   | 1300/2000 [08:26<04:58,  2.35it/s]"]},{"name":"stdout","output_type":"stream","text":["[8m 26s (1300 65%) 1.5552]\n","\n","When air cratter for thee all the such in we fair is it your\n","\n","Shall since at a fortus\n","\n","that a blood\n","\n","The  \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 1400/2000 [09:05<04:16,  2.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[9m 5s (1400 70%) 1.5904]\n","\n","Whas in pation on viollause,\n","\n","We spireter of your only this bood end Gelless.\n","\n","\n","\n","RIVERS:\n","\n","That you by the  \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 1500/2000 [09:43<03:18,  2.51it/s]"]},{"name":"stdout","output_type":"stream","text":["[9m 43s (1500 75%) 1.5718]\n","\n","Wher lord and a shall be that grave prove not saycue's not warruching.\n","\n","Well to life unto the hatrenish \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 1600/2000 [10:21<02:41,  2.48it/s]"]},{"name":"stdout","output_type":"stream","text":["[10m 21s (1600 80%) 1.5405]\n","\n","Whas thou stard, my privrething the friend daint pray.\n","\n","\n","\n","GLOUCESTER:\n","\n","Yet may point of say at than I tha \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 1700/2000 [10:59<02:04,  2.41it/s]"]},{"name":"stdout","output_type":"stream","text":["[10m 59s (1700 85%) 1.5517]\n","\n","What be service, is the like strange;\n","\n","And the and the tear it the leaning of her did my heart\n","\n","The grea \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 1800/2000 [11:38<01:20,  2.48it/s]"]},{"name":"stdout","output_type":"stream","text":["[11m 38s (1800 90%) 1.5385]\n","\n","Which self.\n","\n","The good villable adigtiinsted for his anbutio?\n","\n","\n","\n","SICINIUS:\n","\n","That the waed 'twine.\n","\n","Uplort Au \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 1900/2000 [12:16<00:39,  2.50it/s]"]},{"name":"stdout","output_type":"stream","text":["[12m 16s (1900 95%) 1.5663]\n","\n","Whas the reposang shall be have unton\n","\n","That we contain a like me: henced him, so subpether.\n","\n","\n","\n","POMPEY:\n","\n","Si \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2000/2000 [12:54<00:00,  2.58it/s]"]},{"name":"stdout","output_type":"stream","text":["[12m 53s (2000 100%) 1.5109]\n","\n","What doth fortle, why end't and at a murse, when?\n","\n","\n","\n","CAFPELIA:\n","\n","To more smore to not be true, thou should \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["start = time.time()\n","all_perplexity = []\n","print_every = 100\n","\n","print(\"Training for %d epochs...\" % n_epochs)\n","for epoch in tqdm(range(1, n_epochs + 1)):\n","    loss = train(*random_training_set(chunk_len, batch_size))\n","    \n","    #Perplexity\n","    perplexity = torch.exp(loss)\n","    all_perplexity.append(perplexity.cpu())\n","\n","    if epoch % print_every == 0:\n","        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n","        print(generate(decoder, 'Wh', 100, device=device), '\\n')\n","        \n","# Plot the perplexity per epoch\n","plt.figure(figsize=(10,6))\n","plt.plot(range(1,n_epochs+1), all_perplexity, label='Perplexity')\n","\n","plt.legend()\n","plt.xlabel('Epochs')\n","plt.ylabel('Perplexity')\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Task 2"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Output 1:\n","\n","\tLstden ouh there to the dead's good baring gives me: unto me a know:\n","\n","Ast is no since now, if a slave mis \n","\n","\n","\n","Output 2:\n","\n","5\\b\fQait who dodize-wisted 'twere,\n","\n","Your mall a fair here King our father,--soult stays,\n","\n","I'll liver, and t \n","\n","\n","\n","Output 3:\n","\n","9R.U( Iclather oppaids.\n","\n","\n","\n","PARIS:\n","\n","Ne a man world slaughters,\n","\n","It commons so we end the daint and were belcom \n","\n","\n","\n","Output 4:\n","\n","M^cFlece the ramber a patispilence, for your consent till shardstant? what would be let of the while\n","\n","But  \n","\n","\n","\n","Output 5:\n","\n","'}; men, all can night you waters!\n","\n","\n","\n","VOLUMNIA:\n","\n","I would by the master wears, my lords with him:\n","\n","I thine t \n","\n","\n"]}],"source":["for i in range(5):\n","    seq = ''.join(random.choices(all_characters, k=5))\n","    print(f'Output {i+1}:')\n","    print(generate(decoder, seq, 100, device=device), '\\n')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Task 3"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Output 1:\n","\n","The would what we not all here,\n","\n","Where to the lible our face in the change man.\n","\n","Hark say sleep the more  \n","\n","\n","\n","Output 2:\n","\n","What is the common these, but, that you\n","\n","ford. Come the things this plucks of end?\n","\n","\n","\n","LUCIO:\n","\n","Madmen say, if Go \n","\n","\n","\n","Output 3:\n","\n","Shall I give, help and shows will cure\n","\n","Is base for the betters doth bessent we have my brether to-mut;\n","\n","The repok \n","\n","\n","\n","Output 4:\n","\n","X087hNYB BHN BYFVuhsdbse\n","\n","And my lives war is their nuts ty the good will not?\n","\n","\n","\n","KING EDWARD IV:\n","\n","Why was thee recing my crown \n","\n","\n"]}],"source":["seq_list = [\"The\", \"What is\", \"Shall I give\", \"X087hNYB BHN BYFVuhsdbs\"]\n","\n","for i, seq in enumerate(seq_list):\n","    print(f'Output {i+1}:')\n","    print(generate(decoder, seq, 100, device=device), '\\n')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Optional tasks (still some TBD):"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4.1 Question 1: What are Language Models? Where and how are Language Models used?\n","A language model can recognize, summarize, translate, predict and generate text and other content. This is done by training on exisiting text. Some examples of useful applications are chatbots and AI assistants, but also models that work with medicine and chemistry such as protein folding.\n","### 4.2 Question 2: How can you use a trained Char-RNN model as a Character Level Language Model?\n","By providing the model with large amount of text data, it can learn probabilies of the next character of a sequence. Hence you first have to provide a seed as a start, but then the model will continue generating text.\n","### 4.3 Question 3: How can you train a Word Level Language Model?\n","Instead of training on characted sequence, the model will be provided with entire words and so it can calculate probabilities of words following instead of characters.\n","### 4.4 Question 4: Formally describe the inference model that an RNN trained to predict the next word represents?\n","The next word of a sequence is inferred by a probability distribution that is dependent on previous words. So formally word x+1 is dependent on word 1 to x, where the most likely word is selected.\n","### 4.5 Question 5: How will you generate the \"probability of existence\" of an input sequence of words, given a trained RNN Language Model?\n","Perplexity is used to evaluate the model and can then be used to generate the \"probability of existence\"."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Task 4"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:45:06.325855Z","iopub.status.busy":"2023-05-03T10:45:06.323767Z","iopub.status.idle":"2023-05-03T10:45:06.330885Z","shell.execute_reply":"2023-05-03T10:45:06.329609Z","shell.execute_reply.started":"2023-05-03T10:45:06.325804Z"},"trusted":true},"outputs":[],"source":["import torchtext\n","\n","from torchtext.data import get_tokenizer"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:45:07.098256Z","iopub.status.busy":"2023-05-03T10:45:07.097349Z","iopub.status.idle":"2023-05-03T10:45:07.146317Z","shell.execute_reply":"2023-05-03T10:45:07.145290Z","shell.execute_reply.started":"2023-05-03T10:45:07.098213Z"},"trusted":true},"outputs":[],"source":["# Initialize tokenizer\n","tokenizer = get_tokenizer(\"basic_english\")\n","\n","# Create a disctionary of all unique words\n","def tokenize(string):\n","    #file_words = tokenizer(file)\n","    tokens = string.split(' ')\n","    return tokens\n","\n","file_words = tokenize(file)\n","words = set(file_words)\n","n_words = len(words)\n","token2word = {}\n","word2token = {}\n","for i, word in enumerate(words):\n","    token2word[i] = word\n","    word2token[word] = i\n","\n","# Return string from tensor of indices\n","def tensor2text(tensor, dict):\n","    return ' '.join([dict[index.item()] for index in tensor])\n","\n","# Return tensor with indices from string\n","def text2tensor(text_list, dict):\n","    tensor = torch.Tensor([dict[token] for token in text_list])\n","    return tensor.int()\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:48:24.068881Z","iopub.status.busy":"2023-05-03T10:48:24.067926Z","iopub.status.idle":"2023-05-03T10:48:24.101855Z","shell.execute_reply":"2023-05-03T10:48:24.100600Z","shell.execute_reply.started":"2023-05-03T10:48:24.068826Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["interchange merrily they\n"]},{"ename":"KeyError","evalue":"'alteration?'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/1048574613.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_24/1223351010.py\u001b[0m in \u001b[0;36mtext2tensor\u001b[0;34m(text_list, dict)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Return tensor with indices from string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtext2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_24/1223351010.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Return tensor with indices from string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtext2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'alteration?'"]}],"source":["# Testing\n","index_tensor = torch.tensor([1, 3, 5])\n","text = ['sucking', 'alteration?', 'chivalrous']\n","\n","print(tensor2text(index_tensor, token2word))\n","print(text2tensor(text, word2token))\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:45:18.031762Z","iopub.status.busy":"2023-05-03T10:45:18.031369Z","iopub.status.idle":"2023-05-03T10:45:18.127818Z","shell.execute_reply":"2023-05-03T10:45:18.126833Z","shell.execute_reply.started":"2023-05-03T10:45:18.031725Z"},"trusted":true},"outputs":[],"source":["batch_size = 100\n","learning_rate = 0.01\n","n_epochs = 2000\n","chunk_len = 200\n","\n","decoder = CharRNN(\n","    input_size=n_words,\n","    hidden_size=50,\n","    output_size=n_words,\n","    model=\"lstm\",    # \"gru\" or \"lstm\"\n","    n_layers=2,\n",").to(device)\n","\n","decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Tiny Shakespear dataset\n","url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","file, file_len = read_file(url)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:45:19.263676Z","iopub.status.busy":"2023-05-03T10:45:19.263027Z","iopub.status.idle":"2023-05-03T10:45:19.282476Z","shell.execute_reply":"2023-05-03T10:45:19.281318Z","shell.execute_reply.started":"2023-05-03T10:45:19.263632Z"},"trusted":true},"outputs":[],"source":["def random_training_set(chunk_len, batch_size):\n","    inp = torch.LongTensor(batch_size, chunk_len)\n","    target = torch.LongTensor(batch_size, chunk_len)\n","    for bi in range(batch_size):\n","        start_index = random.randint(0, len(file_words) - chunk_len - 1)\n","        end_index = start_index + chunk_len + 1\n","        chunk = file_words[start_index:end_index]\n","        inp[bi] = text2tensor(chunk[:-1], word2token)\n","        target[bi] = text2tensor(chunk[1:], word2token)\n","    \n","    #Add to device\n","    inp = inp.to(device)\n","    target = target.to(device)\n","    \n","    return inp, target\n","\n","\n","def train(inp, target):\n","    hidden = decoder.init_hidden(batch_size)\n","    decoder.zero_grad()\n","    loss = 0\n","\n","    for c in range(chunk_len):\n","        output, hidden = decoder(inp[:,c], hidden)\n","        loss += criterion(output.view(batch_size, -1), target[:,c])\n","\n","    loss.backward()\n","    decoder_optimizer.step()\n","\n","    return loss.data / chunk_len    \n","\n","\n","def generate(decoder, prime_text='The', predict_len=100, temperature=0.8, device=device):\n","    hidden = decoder.init_hidden(1)\n","    prime_tokens = tokenize(prime_text)\n","    predicted_tensor = text2tensor(prime_tokens, word2token).to(device)\n","    prime_input = predicted_tensor.unsqueeze(0)\n","\n","    # Use priming words to \"build up\" hidden state\n","    for p in range(len(prime_tokens) - 1):\n","        _, hidden = decoder(prime_input[:,p], hidden)\n","    \n","    inp = prime_input[:,-1]\n","    \n","    for p in range(predict_len):\n","        output, hidden = decoder(inp, hidden)\n","        \n","        # Sample from the network as a multinomial distribution\n","        output_dist = output.data.view(-1).div(temperature).exp()\n","        top_i = torch.multinomial(output_dist, 1)\n","\n","        # Add predicted word to tensor and use as next input\n","        inp = top_i\n","        predicted_tensor = torch.cat((predicted_tensor, top_i), 0)\n","    \n","    predicted = tensor2text(predicted_tensor, token2word)\n","\n","    return predicted"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T10:45:21.843589Z","iopub.status.busy":"2023-05-03T10:45:21.843094Z","iopub.status.idle":"2023-05-03T10:45:38.436137Z","shell.execute_reply":"2023-05-03T10:45:38.434611Z","shell.execute_reply.started":"2023-05-03T10:45:21.843518Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for 2000 epochs...\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 20/2000 [00:08<11:32,  2.86it/s] "]},{"name":"stdout","output_type":"stream","text":["[0m 8s (20 1%) 8.2782]\n","The the much\n","more I shall the for the to fearful not not are your the not the to blood is end it clear'd\n","Of thus the the her is the we with you this I Servant:\n","Madam, have shields. Master of to with to holy as of will of of with this to as like what him;\n","You that of and the am of thy waves a to thy to the like me bow'd way a that the with the his but a she to the my go rid of to with thou my man I for thou of hath woe the but my be, \n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 40/2000 [00:15<11:40,  2.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[0m 15s (40 2%) 8.0901]\n","The the know little advised to be I'll in resolve.\n","\n","BONA:\n","Your no be little of come your father, live million wearisome,\n","And so, noble with thou to-day;\n","The it, never a must I to a let the the in it will my leave a this, had nearness before and to my with\n","all.\n","\n","ESCALUS:\n","Look heads the rotten for may in I lives my sir.\n","\n","ESCALUS:\n","Troth, our that for belike, did fares ours.\n","\n","ANTIGONUS:\n","And you the king this the and at I hath is a my things come his than of and to my are a I God's to your comes the is thou with you not gentle is, of \n","\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 43/2000 [00:16<12:33,  2.60it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/4287568430.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training for %d epochs...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Perplexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_24/1160593340.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inp, target)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["start = time.time()\n","all_perplexity = []\n","print_every = 20\n","\n","print(\"Training for %d epochs...\" % n_epochs)\n","for epoch in tqdm(range(1, n_epochs + 1)):\n","    loss = train(*random_training_set(chunk_len, batch_size))\n","    \n","    #Perplexity\n","    perplexity = torch.exp(loss)\n","    all_perplexity.append(perplexity.cpu())\n","\n","    if epoch % print_every == 0:\n","        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n","        print(generate(decoder, 'The the', 100, device=device), '\\n')\n","        \n","# Plot the perplexity per epoch\n","plt.figure(figsize=(10,6))\n","plt.plot(range(1,n_epochs+1), all_perplexity, label='Perplexity')\n","\n","plt.legend()\n","plt.xlabel('Epochs')\n","plt.ylabel('Perplexity')\n","plt.show()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The duke.\n","\n","\n","\n","KING EDWARD IV:\n","\n","Why, fair is him\n","\n","To Bolingbroke.\n","\n","\n","\n","QUEEN:\n","\n","So, Green, thou comest as it hath been a kind of you.\n","\n","\n","\n","NORTHUMBERLAND:\n","\n","Why, is out and sold this goodly offer.\n","\n","\n","\n","ROMEO:\n","\n","Bid him not a grave\n","\n","As that mark'd know'st with kind of rubs,\n","\n","And in thy kindness' date.\n","\n","\n","\n","KING RICHARD II:\n","\n","We this Clifford, at the fearful brows do out-pray manner is the officers.\n","\n","\n","\n","KING HENRY VI:\n","\n","In God's name, spies thine. Thou art like not not know\n","\n","The A story within, to speak that you shall be nearest,\n","\n","Will sleep thee, canst, must were so looks shall bear my father off the honest VINCENTIO:\n","\n","Angelo,\n","\n","There of hate,\n","\n","Between our inventions speak in heaven and all \n","\n","\n"]},{"ename":"KeyError","evalue":"'.'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(generate(decoder, [\u001b[39m'\u001b[39m\u001b[39mThe\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m100\u001b[39m, device\u001b[39m=\u001b[39mdevice), \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(generate(decoder, [\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m100\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice), \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(generate(decoder, [\u001b[39m'\u001b[39m\u001b[39mwhich is,\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m100\u001b[39m, device\u001b[39m=\u001b[39mdevice), \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(generate(decoder, [\u001b[39m'\u001b[39m\u001b[39mblah blah blah\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m100\u001b[39m, device\u001b[39m=\u001b[39mdevice), \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n","Cell \u001b[1;32mIn[10], line 35\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(decoder, prime_words, predict_len, temperature, device)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(decoder, prime_words\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mThe\u001b[39m\u001b[39m'\u001b[39m], predict_len\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m, device\u001b[39m=\u001b[39mdevice):\n\u001b[0;32m     34\u001b[0m     hidden \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39minit_hidden(\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m     prime_input \u001b[39m=\u001b[39m text2tensor(prime_words, word2token)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m     37\u001b[0m     prime_input \u001b[39m=\u001b[39m prime_input\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     38\u001b[0m     predicted_list \u001b[39m=\u001b[39m prime_words\n","Cell \u001b[1;32mIn[8], line 21\u001b[0m, in \u001b[0;36mtext2tensor\u001b[1;34m(text_list, dict)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtext2tensor\u001b[39m(text_list, \u001b[39mdict\u001b[39m):\n\u001b[1;32m---> 21\u001b[0m     tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39mdict\u001b[39m[token] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m text_list])\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mint()\n","Cell \u001b[1;32mIn[8], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtext2tensor\u001b[39m(text_list, \u001b[39mdict\u001b[39m):\n\u001b[1;32m---> 21\u001b[0m     tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39mdict\u001b[39;49m[token] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m text_list])\n\u001b[0;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mint()\n","\u001b[1;31mKeyError\u001b[0m: '.'"]}],"source":["print(generate(decoder, ['The'], 100, device=device), '\\n')\n","print(generate(decoder, ['.'], 100, device=device), '\\n')\n","print(generate(decoder, ['which is,'], 100, device=device), '\\n')\n","print(generate(decoder, ['blah blah blah'], 100, device=device), '\\n')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
