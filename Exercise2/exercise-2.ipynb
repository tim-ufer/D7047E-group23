{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e978b11",
   "metadata": {},
   "source": [
    "Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edd45b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f0a754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "\n",
    "# Making the code device-agnostic\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.1.2 Transfer Learning from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Train augmentations\n",
    "train_test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(root='D:/Dev/auto_download_data/D7047E/CIFAR10',\n",
    "                                             train=True,\n",
    "                                             download=True,\n",
    "                                             transform=train_test_transform)\n",
    "cifar10_test = datasets.CIFAR10(root='D:/Dev/auto_download_data/D7047E/CIFAR10',\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=train_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba6b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 100\n",
    "SHUFFLE = True\n",
    "LEARNING_RATE = 0.0001\n",
    "epochs = 1\n",
    "\n",
    "# Train 80 %, Validation 20 % of test set\n",
    "train_set, val_set = torch.utils.data.random_split(cifar10_train, [0.8, 0.2], generator=torch.Generator())\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "test_loader = DataLoader(cifar10_test, batch_size=BATCH_SIZE, shuffle=SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78dbcc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "       \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    #tb = SummaryWriter()\n",
    "    \n",
    "    best_val_loss = 999999\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss_sum = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_nr, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # Convert to one hot tensors\n",
    "            labels = F.one_hot(labels, 10).float()\n",
    "\n",
    "            # In case of GPU used:\n",
    "            if device == 'cuda':\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, labels)\n",
    "            train_loss = loss.item() * inputs.size(0)\n",
    "            train_loss_sum += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            for i, _ in enumerate(predictions):\n",
    "                if torch.argmax(labels[i]) == torch.argmax(predictions[i]):\n",
    "                    train_correct += 1\n",
    "                train_total += 1\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clear\n",
    "            optimizer.zero_grad()\n",
    "                       \n",
    "            # Print the epoch and loss\n",
    "            print('\\r', f'Epoch {epoch+1} - Train loss: {train_loss_sum / train_total} - Accuracy: {train_correct / train_total:.2f}', end='')\n",
    "            \n",
    "            # Add to tensorboard\n",
    "            #tb.add_scalar(\"Loss\", train_loss, batch_nr)\n",
    "            #tb.add_scalar(\"Accuracy\", train_correct / train_total, batch_nr)\n",
    "\n",
    "            #tb.add_histogram(\"conv1.bias\", model.conv1.bias, batch_nr)\n",
    "            #tb.add_histogram(\"conv1.weight\", model.conv1.weight, batch_nr)\n",
    "            #tb.add_histogram(\"conv2.bias\", model.conv2.bias, batch_nr)\n",
    "            #tb.add_histogram(\"conv2.weight\", model.conv2.weight, batch_nr)\n",
    "                \n",
    "        # Add the loss to the total epoch loss (item() turns a PyTorch scalar into a normal Python datatype)\n",
    "        train_losses.append(train_loss_sum / train_total)\n",
    "        train_accuracies.append(train_correct / train_total)\n",
    "                \n",
    "        # Print the epoch and loss\n",
    "        #print(f'Epoch {epoch+1} - Train loss: {train_loss_sum / train_total} - Accuracy: {train_correct / train_total:.2f}')\n",
    "        print('')\n",
    "        \n",
    "        val_loss_sum = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        for batch_nr, (inputs, labels) in enumerate(val_loader):\n",
    "            \n",
    "            # Convert to one hot tensors\n",
    "            labels = F.one_hot(labels, 10).float()\n",
    "\n",
    "            # In case of GPU used:\n",
    "            if device == 'cuda':\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_loss_sum += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            for i, _ in enumerate(predictions):\n",
    "                if torch.argmax(labels[i]) == torch.argmax(predictions[i]):\n",
    "                    val_correct += 1\n",
    "                val_total += 1\n",
    "                        \n",
    "        # Add the loss to the total epoch loss (item() turns a PyTorch scalar into a normal Python datatype)\n",
    "        val_losses.append(val_loss_sum / val_total)\n",
    "        val_accuracies.append(val_correct / val_total)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss_sum < best_val_loss:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_val_loss = val_loss_sum\n",
    "            print(f'New best model in epoch {epoch}!')\n",
    "                \n",
    "        # Print the epoch and loss\n",
    "        print(f'Epoch {epoch+1} - Validation loss: {val_loss_sum / val_total} - Accuracy: {val_correct / val_total:.2f}')\n",
    "        print('')\n",
    "        \n",
    "    #tb.close()\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "\n",
    "def test_model(model, criterion, test_loader):\n",
    "       \n",
    "    test_losses = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "        \n",
    "    test_loss_sum = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    for batch_nr, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "        # Convert to one hot tensors\n",
    "        labels = F.one_hot(labels, 10).float()\n",
    "        \n",
    "        for label in labels:\n",
    "            y_true.append(torch.argmax(label)) # Save Truth\n",
    "\n",
    "        # In case of GPU used:\n",
    "        if device == 'cuda':\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(inputs)\n",
    "        \n",
    "        for prediction in predictions:\n",
    "            y_pred.append(torch.argmax(prediction)) # Save Prediction\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        test_loss_sum += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        for i, _ in enumerate(predictions):\n",
    "            if torch.argmax(labels[i]) == torch.argmax(predictions[i]):\n",
    "                test_correct += 1\n",
    "            test_total += 1\n",
    "\n",
    "    # Add the loss to the total epoch loss (item() turns a PyTorch scalar into a normal Python datatype)\n",
    "    test_losses.append(test_loss_sum / test_total)\n",
    "\n",
    "    # Print the epoch and loss\n",
    "    print(f'Test loss: {test_loss_sum / test_total} - Accuracy: {test_correct / test_total:.2f}')\n",
    "       \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5db527f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 - Train loss: 2.247556603550911 - Accuracy: 0.199\n",
      "New best model in epoch 0!\n",
      "Epoch 1 - Validation loss: 2.1707798171043398 - Accuracy: 0.23\n",
      "\n",
      "Test loss: 2.1762973260879517 - Accuracy: 0.22\n"
     ]
    }
   ],
   "source": [
    "# Fine tuning\n",
    "#alexnet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "alexnet = models.alexnet(weights='DEFAULT')\n",
    "\n",
    "# Add extra output layer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Implement the forward function in the network\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "extra_layer = Net()\n",
    "    \n",
    "model_ft = nn.Sequential(alexnet, extra_layer)\n",
    "# In case of GPU used:\n",
    "if device == 'cuda':\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "# Define our loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "optimizer = torch.optim.SGD(model_ft.parameters(), LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model_ft, criterion, optimizer, train_loader, val_loader, epochs)\n",
    "\n",
    "# Test the model\n",
    "tested_model = test_model(trained_model, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e75e33a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 - Train loss: 1.9882444095611573 - Accuracy: 0.33\n",
      "New best model in epoch 0!\n",
      "Epoch 1 - Validation loss: 1.6334615492820739 - Accuracy: 0.43\n",
      "\n",
      "Test loss: 1.6302244079113006 - Accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "#alexnet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "alexnet = models.alexnet(weights='DEFAULT')\n",
    "\n",
    "# Freeze all layers of the alexnet model\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add extra output layer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Implement the forward function in the network\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "extra_layer = Net()\n",
    "\n",
    "model_fe = nn.Sequential(alexnet, extra_layer)\n",
    "# In case of GPU used:\n",
    "if device == 'cuda':\n",
    "    model_fe = model_fe.to(device)\n",
    "\n",
    "# Define our loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "optimizer = torch.optim.SGD(model_fe.parameters(), LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model_fe, criterion, optimizer, train_loader, val_loader, epochs)\n",
    "\n",
    "# Test the model\n",
    "tested_model = test_model(trained_model, criterion, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fine tuning is retraining the model from some default weights.\n",
    "Feature extraction is using default weights but not updating them at all. Omly weight updates are for the output layer we added ourselves.\n",
    "This means Feature extraction should be faster, but fine tuning more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train augmentations\n",
    "train_test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_train = datasets.MNIST(root='D:/Dev/auto_download_data/D7047E/MNIST',\n",
    "                                             train=True,\n",
    "                                             download=True,\n",
    "                                             transform=train_test_transform)\n",
    "mnist_test = datasets.MNIST(root='D:/Dev/auto_download_data/D7047E/MNIST',\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=train_test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.1.2 Transfer Learning with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 100\n",
    "SHUFFLE = True\n",
    "LEARNING_RATE = 0.01\n",
    "epochs = 3\n",
    "\n",
    "# Train 80 %, Validation 20 % of test set\n",
    "train_set, val_set = torch.utils.data.random_split(mnist_train, [0.8, 0.2], generator=torch.Generator())\n",
    "\n",
    "train_loader_mnist = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "val_loader_mnist = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "test_loader_mnist = DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 - Train loss: 2.2783682882785796 - Accuracy: 0.26\n",
      "New best model in epoch 0!\n",
      "Epoch 1 - Validation loss: 2.223879504203796 - Accuracy: 0.49\n",
      "\n",
      " Epoch 2 - Train loss: 1.31750753428787 - Accuracy: 0.7333\n",
      "New best model in epoch 1!\n",
      "Epoch 2 - Validation loss: 0.511066680898269 - Accuracy: 0.85\n",
      "\n",
      " Epoch 3 - Train loss: 0.3959876643648992 - Accuracy: 0.888\n",
      "New best model in epoch 2!\n",
      "Epoch 3 - Validation loss: 0.33624666146934035 - Accuracy: 0.90\n",
      "\n",
      "Test loss: 0.3083732095360756 - Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_mnist = Net()\n",
    "# In case of GPU used:\n",
    "if device == 'cuda':\n",
    "    model_mnist = model_mnist.to(device)\n",
    "\n",
    "# Define our loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "#optimizer = torch.optim.Adam(model_mnist.parameters(), LEARNING_RATE)\n",
    "optimizer_mnist = torch.optim.SGD(model_mnist.parameters(), LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "trained_model_mnist = train_model(model_mnist, criterion, optimizer_mnist, train_loader_mnist, val_loader_mnist, epochs)\n",
    "\n",
    "# Test the model\n",
    "test_model(trained_model_mnist, criterion, test_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: D:/Dev/auto_download_data/D7047E/SVHN\\train_32x32.mat\n",
      "Using downloaded and verified file: D:/Dev/auto_download_data/D7047E/SVHN\\test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# Train augmentations\n",
    "train_test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "svhn_train = datasets.SVHN(root='D:/Dev/auto_download_data/D7047E/SVHN',\n",
    "                                             split='train',\n",
    "                                             download=True,\n",
    "                                             transform=train_test_transform)\n",
    "svhn_test = datasets.SVHN(root='D:/Dev/auto_download_data/D7047E/SVHN',\n",
    "                                            split='test',\n",
    "                                            download=True,\n",
    "                                            transform=train_test_transform)\n",
    "\n",
    "# Train 80 %, Validation 20 % of test set\n",
    "train_set, val_set = torch.utils.data.random_split(svhn_train, [0.8, 0.2], generator=torch.Generator())\n",
    "\n",
    "train_loader_svhn = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "val_loader_svhn = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "test_loader_svhn = DataLoader(svhn_test, batch_size=BATCH_SIZE, shuffle=SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 - Train loss: 2.306025738985112 - Accuracy: 0.155\n",
      "New best model in epoch 0!\n",
      "Epoch 1 - Validation loss: 2.3058769437170104 - Accuracy: 0.14\n",
      "\n",
      " Epoch 2 - Train loss: 2.306025737325303 - Accuracy: 0.155\n",
      "Epoch 2 - Validation loss: 2.3058769501449223 - Accuracy: 0.14\n",
      "\n",
      " Epoch 3 - Train loss: 2.306025733842958 - Accuracy: 0.155\n",
      "New best model in epoch 2!\n",
      "Epoch 3 - Validation loss: 2.3058769370612735 - Accuracy: 0.14\n",
      "\n",
      "Test loss: 2.3053753221775026 - Accuracy: 0.16\n"
     ]
    }
   ],
   "source": [
    "# Train model from scratch with SVHN\n",
    "model_svhn = Net()\n",
    "# In case of GPU used:\n",
    "if device == 'cuda':\n",
    "    model_svhn = model_svhn.to(device)\n",
    "\n",
    "# Define our loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "#optimizer = torch.optim.Adam(model_svhn.parameters(), LEARNING_RATE)\n",
    "optimizer_svhn = torch.optim.SGD(model_svhn.parameters(), LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "trained_model_svhn = train_model(model_svhn, criterion, optimizer_svhn, train_loader_svhn, val_loader_svhn, epochs)\n",
    "\n",
    "# Test the model\n",
    "test_model(trained_model_svhn, criterion, test_loader_svhn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 5.06914457215366 - Accuracy: 0.12\n"
     ]
    }
   ],
   "source": [
    "# Test the MNIST model for SVHN data\n",
    "\n",
    "# Test the model\n",
    "test_model(trained_model_mnist, criterion, test_loader_svhn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 - Train loss: 5.308376311604953 - Accuracy: 0.111\n",
      "New best model in epoch 0!\n",
      "Epoch 1 - Validation loss: 5.33636589924489 - Accuracy: 0.10\n",
      "\n",
      " Epoch 2 - Train loss: 5.3083763145014835 - Accuracy: 0.11\n",
      "New best model in epoch 1!\n",
      "Epoch 2 - Validation loss: 5.336365867544706 - Accuracy: 0.10\n",
      "\n",
      " Epoch 3 - Train loss: 5.308376311621227 - Accuracy: 0.111\n",
      "New best model in epoch 2!\n",
      "Epoch 3 - Validation loss: 5.336365851336604 - Accuracy: 0.10\n",
      "\n",
      "Test loss: 5.444234856521709 - Accuracy: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning from MNIST to SVHN\n",
    "\n",
    "# Define our optimizer\n",
    "optimizer_svhn = torch.optim.Adam(model_svhn.parameters(), LEARNING_RATE)\n",
    "#optimizer = torch.optim.SGD(model_mnist.parameters(), LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "trained_model_svhn = train_model(trained_model_mnist, criterion, optimizer_mnist, train_loader_svhn, val_loader_svhn, epochs)\n",
    "\n",
    "# Test the model\n",
    "test_model(trained_model_svhn, criterion, test_loader_svhn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is available: True\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Device 0: <torch.cuda.device object at 0x000002441C9E1120>\n",
      "Get device name 0: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "print(f'Is available: {torch.cuda.is_available()}')\n",
    "print(f'Device count: {torch.cuda.device_count()}')\n",
    "print(f'Current device: {torch.cuda.current_device()}')\n",
    "print(f'Device 0: {torch.cuda.device(0)}')\n",
    "print(f'Get device name 0: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
