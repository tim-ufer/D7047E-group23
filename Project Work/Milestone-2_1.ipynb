{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Author Anthony Colton\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')\n\n# Making the code device-agnostic\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"# HELPER FUNCTIONS\n\nimport random\nimport torchvision.models as models\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision import transforms\n\ndef load_data(path, label, images, labels):\n    # Loop through the normal images and append them to the images list with a label of 0\n    for filename in os.listdir(path):\n        if filename.endswith(\".jpeg\"):\n            img = Image.open(os.path.join(path, filename))\n            images.append(img)\n            labels.append(label)\n\ndef get_data(normal_path, pnumonia_path):\n    images = []\n    labels = []\n    \n    load_data(normal_path, 0, images, labels)\n    load_data(pnumonia_path, 1, images, labels)\n    \n    return images, labels\n\n\ndef shuffle_data(images, labels):\n    # Shuffle the images and labels in the same order\n    zipped_data = list(zip(images, labels))\n    random.shuffle(zipped_data)\n    images, labels = zip(*zipped_data)\n    return images, labels\n\n\ndef get_model_resnet18(dropout = 0):\n    # Load the ResNet-18 model\n    resnet18 = models.resnet18(pretrained=True)\n\n    # modify input layer to accept grayscale images and add dropout\n    resnet18.conv1 = nn.Sequential(\n        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        #,nn.Dropout2d(p=0.1)\n    )\n\n    # Add dropout between each hidden layer except for the output layer\n    num_classes = 2  # replace with the number of classes in your task\n    resnet18.fc = nn.Sequential(\n        nn.Linear(resnet18.fc.in_features, 512),\n        nn.ReLU(),\n        nn.Dropout(p=dropout),\n        nn.Linear(512, num_classes),\n    )\n\n    return resnet18.to(device)\n\n\"\"\"def get_model_mobilenetv2(dropout=0):\n    # Load the MobileNetV2 model\n    mobilenetv2 = models.mobilenet_v2(pretrained=True)\n\n    # Modify input layer to accept grayscale images and add dropout\n    mobilenetv2.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n\n    # Add dropout to the classifier\n    num_classes = 2  # Replace with the number of classes in your task\n    mobilenetv2.classifier[1] = nn.Sequential(\n        nn.Dropout(p=dropout),\n        nn.Linear(mobilenetv2.last_channel, num_classes),\n    )\n\n    return mobilenetv2.to(device)\"\"\"\n\n# Added Batch normalization together with dropout to combat overfitting\ndef get_model_mobilenetv2(dropout=0):\n    # Load the MobileNetV2 model\n    mobilenetv2 = models.mobilenet_v2(pretrained=True)\n\n    # Modify input layer to accept grayscale images\n    mobilenetv2.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n\n    # Add batch normalization to the features\n    for module in mobilenetv2.features.modules():\n        if isinstance(module, nn.Conv2d):\n            module = nn.Sequential(module, nn.BatchNorm2d(module.out_channels))\n\n    # Add dropout to the classifier\n    num_classes = 2  # Replace with the number of classes in your task\n    mobilenetv2.classifier[1] = nn.Sequential(\n        nn.Dropout(p=dropout),\n        nn.Linear(mobilenetv2.last_channel, num_classes),\n    )\n\n    return mobilenetv2.to(device)\n\n\n# Transforms to apply to all images\ntransform = transforms.Compose([\n    transforms.Resize((240, 240)),  # resize to a fixed size\n    transforms.CenterCrop((224, 224)),  # crop the center of the image\n    transforms.Grayscale(num_output_channels=1),  # convert the image to grayscale\n    transforms.ToTensor()  # convert images to PyTorch tensors\n    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization\n])\n\n# Transforms to apply to aguemented images\naugment_transforms = transforms.Compose([\n    transforms.Resize((240, 240)),  # resize to a fixed size\n    transforms.RandomRotation(4),  # randomly rotate the image by up to 5 degrees\n    transforms.CenterCrop((224, 224)), # crop the center of the image\n    #transforms.RandomHorizontalFlip(),  # randomly flip the image horizontally\n    #transforms.RandomVerticalFlip(),  # randomly flip the image vertically\n    #transforms.ColorJitter(brightness=0.05, contrast=0.05),  # add random brightness and contrast change\n    transforms.Grayscale(num_output_channels=1),  # convert the image to grayscale\n    transforms.ToTensor()  # convert images to PyTorch tensors\n])\n\ndef apply_transforms(imgs_to_transform):\n    # apply the transforms to each image in the list\n    images_transformed = []\n    for img in imgs_to_transform:\n        images_transformed.append(transform(img))\n    return images_transformed\n\ndef apply_augment_transforms(imgs_to_transform):\n    # apply the transforms to each image in the list\n    images_transformed = []\n    for img in imgs_to_transform:\n        images_transformed.append(transform(img))\n    return images_transformed\n\ndef plot_epoch_accuracy(accuracy_list):\n    num_epochs = len(accuracy_list[0])\n    num_folds = len(accuracy_list)\n\n    # Initialize list to store accuracy for each epoch\n    epoch_accuracy_list = [[] for i in range(num_epochs)]\n\n    # Populate list with accuracy for each epoch\n    for fold, fold_accuracy in enumerate(accuracy_list):\n        for epoch, accuracy in enumerate(fold_accuracy):\n            epoch_accuracy_list[epoch].append((fold+1, accuracy))\n\n    # Plot accuracy for each epoch\n    for epoch, epoch_accuracy in enumerate(epoch_accuracy_list):\n        if epoch_accuracy:\n            folds, accuracy = zip(*epoch_accuracy)\n            #folds, accuracy = zip(*[(f.cpu().numpy(), a.cpu().numpy()) for f, a in epoch_accuracy])\n            plt.plot(folds, accuracy, label='Epoch {}'.format(epoch+1))\n\n    # Set axis labels and legend\n    plt.xlabel('Fold')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the data into sets","metadata":{}},{"cell_type":"code","source":"# LOAD THE DATA INTO SETS\n\n# Define the paths to the image files\ntrain_normal_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL/'\ntrain_pneumonia_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA/'\nval_normal_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/val/NORMAL/'\nval_pneumonia_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/val/PNEUMONIA/'\n\n# Create empty lists to store the images and their labels\ntrain_images = []\ntrain_labels = []\n#val_images = []\n#val_labels = []\n\ntrain_images, train_labels = get_data(train_normal_path, train_pneumonia_path)\n#val_images, val_labels = get_data(val_normal_path, val_pneumonia_path)\n\nprint(\"train size: \", len(train_images))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transforms for preprocessing the images","metadata":{}},{"cell_type":"code","source":"# TRANSFORMS FOR PREPROCESSING THE IMAGES\n\n# apply the transforms to each image in the list\naugmnent_normal_images = train_images[:1341]\naugmnent_normal_labels = train_labels[:1341]\n\ntrain_images = apply_augment_transforms(train_images)\n\ntrain_images += apply_augment_transforms(augmnent_normal_images)\ntrain_labels += augmnent_normal_labels\n\n# Shuffle the images and labels in the same order\ntrain_images, train_labels = shuffle_data(train_images, train_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the models","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport torch.optim as optim\n\ndef train_model_cross_val(dropout, dataset, criterion, num_epochs, batch_size, learning_rate=0.0001, num_folds=5, chosen_model=\"resnet18\"):\n    # Check if CUDA is available, otherwise use CPU.\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Split dataset into folds.\n    kf = KFold(n_splits=num_folds)\n    fold = 0\n\n    # Initialize best model and accuracy\n    best_model = None\n    best_acc = 0.0\n\n    # Keeping track of best models\n    best_epoch_models = []\n    best_epoch_accuracy = [] \n    best_epoch_times_per_fold = []\n    \n    for i in range(num_epochs):\n        best_epoch_models.append(None)\n        best_epoch_accuracy.append(0)\n        best_epoch_times_per_fold.append(0)\n        \n    # Saving accuracy for plot\n    accuracy_list = []\n    for i in range(num_folds):\n        accuracy_list.append([])\n    \n    # Iterate over the folds.\n    for train_indices, val_indices in kf.split(dataset):\n        if chosen_model == \"resnet18\":\n            model = get_model_resnet18(dropout)\n        elif chosen_model == \"mobilenetv2\":\n            model = get_model_mobilenetv2(dropout)\n        elif chosen_model == \"model_detect_pneumonia\":\n            model = model_detect_pneumonia\n        \n        #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.005)\n\n        # Initialize train and validation loaders.\n        train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n        val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n        val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n                    \n        # Best validation accuracy this \n        best_val_acc = 0\n        best_epoch = 0\n        \n        # Iterate over the dataset for each epoch.\n        for epoch in range(num_epochs):\n\n            # Set model to training mode.\n            model.train()\n\n            # Initialize training loss, number of correct predictions, and total number of samples.\n            train_loss_sum = 0.0\n            train_corrects = 0\n            train_total = 0\n\n            # Iterate over the training set.\n            for inputs, labels in train_loader:\n\n                # Move inputs and labels to device.\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                # Reset optimizer gradients.\n                optimizer.zero_grad()\n\n                # Calculate model outputs, loss, and predictions.\n                with torch.set_grad_enabled(True):\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n                    _, preds = torch.max(outputs, 1)\n                    loss.backward()\n                    optimizer.step()\n\n                # Update training loss, number of correct predictions, and total number of samples.\n                train_loss_sum += loss.item() * inputs.size(0)\n                train_total += labels.size(0)\n                train_corrects += torch.sum(preds == labels.data)\n\n            # Calculate training loss and accuracy.\n            train_loss = train_loss_sum / train_total\n            train_acc = train_corrects.double() / train_total\n\n            # Initialize validation loss, number of correct predictions, and total number of samples.\n            val_loss_sum = 0.0\n            val_corrects = 0\n            val_total = 0\n\n            # Set model to evaluation mode.\n            model.eval()\n\n            # Iterate over the validation set.\n            with torch.set_grad_enabled(False):\n                for inputs, labels in val_loader:\n\n                    # Move inputs and labels to device.\n                    inputs, labels = inputs.to(device), labels.to(device)\n\n                    # Calculate model outputs, loss, and predictions.\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n                    _, preds = torch.max(outputs, 1)\n\n                    # Update validation loss, number of correct predictions, and total number of samples.\n                    val_loss_sum += loss.item() * inputs.size(0)\n                    val_total += labels.size(0)\n                    val_corrects += torch.sum(preds == labels.data)\n\n            # Calculate validation loss and accuracy.\n            val_loss = val_loss_sum / val_total\n            val_acc = val_corrects.double() / val_total\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                best_epoch = epoch\n            \n            if val_acc > best_epoch_accuracy[epoch]:\n                best_epoch_models[epoch] = model\n                best_epoch_accuracy[epoch] = val_acc\n            \n            \"\"\"if epoch >= 3 and val_acc > best_epoch_accuracy[epoch]:\n                best_epoch_models[epoch] = model\n                best_epoch_accuracy[epoch] = val_acc\"\"\"\n\n\n            # Print epoch and accuracy\n            print('Epoch [{}/{}], Fold [{}/{}], Training Accuracy: {:.4f}, Validation Accuracy: {:.4f}'.format(epoch+1, num_epochs, fold+1, num_folds, train_acc, val_acc))\n            \n            # Append accuracy for this epoch and fold to list\n            accuracy_list[fold].append(val_acc)\n\n        # Print training and validation accuracy for current fold.\n        print('Fold {}/{}: Best epoch: {} | Best validation Accuracy: {:.4f}'.format(fold+1, num_folds, best_epoch+1, best_val_acc))\n\n        # Update the best epoch\n        best_epoch_times_per_fold[best_epoch] += 1\n\n        # Increment fold counter.\n        fold += 1\n\n        # Clear CUDA cache to avoid out of memory errors.\n        torch.cuda.empty_cache()\n\n    \n    # Find the best model by averaging the epochs across the folds.\n    epoch_averages = [] # index = epoch\n    for i in range(len(accuracy_list[0])):\n        epoch_averages.append(0)\n    \n    for i in range(len(accuracy_list)):\n        for j in range(len(accuracy_list[i])):\n            epoch_averages[j] += accuracy_list[i][j]\n    \n    #epoch_everages_res = []\n    for i in range(len(epoch_averages)):\n        epoch_averages[i] = (epoch_averages[i] / len(accuracy_list[0]))\n    \n    \"\"\"if (np.array(best_epoch_times_per_fold).argmax()) <= 3:\n        best_model = best_epoch_models[-1].clone()\n    else:\n        best_model = best_epoch_models[np.array(best_epoch_times_per_fold).argmax()].clone()\"\"\"\n    best_model = best_epoch_models[np.array(best_epoch_times_per_fold).argmax()]\n    #best_model = best_epoch_models[np.array(best_epoch_times_per_fold).argmax()].clone()\n    \n    print()\n    print(\"Returning the model which performs best over all folds\")\n    print(\"Best epoch (based on highest average): \", torch.tensor(epoch_averages).cpu().numpy().argmax() + 1)\n    \n    # Plot \n    plot_epoch_accuracy(torch.tensor(accuracy_list).cpu().tolist())\n    \n    # Delete variables\n    del best_epoch_models\n    del best_epoch_accuracy\n    del best_epoch_times_per_fold\n    \n    # Return best model.\n    return best_model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the model to detect pneumonia","metadata":{}},{"cell_type":"code","source":"# TRAINING THE MODEL \n\nimport torch.optim as optim\n\nnum_epochs = 5\nlearning_rate_SGD = 0.01\nlearning_rate_adam = 0.0001\nbatch_size = 50\nmomentum = 0.9 # to update learning rate during training for SGD optimizer\ndropout = 0.75\nnum_folds = 5\n\n# Define the loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Create a PyTorch DataLoader for the training and validation sets\ntrain_dataset = torch.utils.data.TensorDataset(torch.stack(train_images), torch.tensor(train_labels))\n\n#model_detect_pneumonia = train_model_cross_val(dropout, train_dataset, criterion, num_epochs, batch_size, learning_rate_adam, num_folds, \"mobilenetv2\")\nmodel_detect_pneumonia = train_model_cross_val(dropout, train_dataset, criterion, num_epochs, batch_size, learning_rate_adam, num_folds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clear data for space\n\ndel train_images\ndel train_labels\n\"\"\"del val_images\ndel val_labels\"\"\"\ndel train_dataset\n#del val_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PART 2: ","metadata":{}},{"cell_type":"markdown","source":"# Get pneumonia dataset","metadata":{}},{"cell_type":"code","source":"# GET DATA\n\ntrain_pneumonia_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA/'\n\n# Normal = 1341\n# bacteria = 2530\n# Virus = 1345\n\nimages = []\nlabels = []\n\nimages_bac = []\nlabels_bac = []\n\nimages_vir = []\nlabels_vir = []\n\nfor filename in os.listdir(train_pneumonia_path):\n    splited = filename.split('_')\n    if splited[1] == \"virus\":\n        img = Image.open(os.path.join(train_pneumonia_path, filename))\n        images_vir.append(img)\n        labels_vir.append(0)\n    elif splited[1] == \"bacteria\":\n        img = Image.open(os.path.join(train_pneumonia_path, filename))\n        images_bac.append(img)\n        labels_bac.append(1)\n\n# apply the transforms to each image in the list\naugmnent_vir_images = images_vir[:1185]\naugmnent_vir_labels = labels_vir[:1185]\n\n\n#images = apply_transforms(images_vir) + apply_transforms(images_bac)\nimages = apply_augment_transforms(images_vir) + apply_augment_transforms(images_bac)\nlabels = labels_vir + labels_bac\n\nimages += apply_augment_transforms(augmnent_vir_images)\nlabels += augmnent_vir_labels\n\n# Shuffle the images and labels in the same order\nimages, labels = shuffle_data(images, labels)\n\nprint(\"pn_images_bac size: \", len(images_bac))\nprint(\"pn_images_vir size: \", len(images_vir) + len(augmnent_vir_images))\nprint()\nprint(\"pn_image size: \", len(images))\nprint(\"pn_labels size: \", len(labels))\n\ndel augmnent_vir_images\ndel augmnent_vir_labels\ndel images_bac\ndel images_vir\ndel labels_bac\ndel labels_vir","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model to detect what type of pneumonia","metadata":{}},{"cell_type":"code","source":"num_epochs = 5\nlearning_rate_SGD = 0.01\nlearning_rate_adam = 0.0001\nbatch_size = 50\nmomentum = 0.9 # to update learning rate during training for SGD optimizer\ndropout = 0.5\nnum_folds = 5\n\ncriterion = nn.CrossEntropyLoss()\n\n# Create dataset for training\ndataset = torch.utils.data.TensorDataset(torch.stack(images), torch.tensor(labels))\n\n# Train the model\nmodel_detect_type_pneumonia = train_model_cross_val(dropout, dataset, criterion, num_epochs, batch_size, learning_rate_adam, num_folds, \"mobilenetv2\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CLEAR VARIABLES FOR SPACE\ndel images\ndel labels\ndel dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function to test each model seperately","metadata":{}},{"cell_type":"code","source":"# TEST THE MODEL\n\ndef test_model(model, test_loader, criterion):\n    \n    # Check if CUDA is available, otherwise use CPU.\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Initialize test loss, number of correct predictions, and total number of samples.\n    test_loss_sum = 0.0\n    test_corrects = 0\n    test_total = 0\n\n    # Set model to evaluation mode.\n    model.eval()\n    \n    # Iterate over the test set.\n    with torch.set_grad_enabled(False):\n        for inputs, labels in test_loader:\n            \n            # Move inputs and labels to device.\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Calculate model outputs, loss, and predictions.\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            _, preds = torch.max(outputs, 1)\n            \n            # Update test loss, number of correct predictions, and total number of samples.\n            test_loss_sum += loss.item() * inputs.size(0)\n            test_total += labels.size(0)\n            test_corrects += torch.sum(preds == labels.data)\n\n    # Calculate test loss and accuracy.\n    test_loss = test_loss_sum / test_total\n    test_acc = test_corrects.double() / test_total\n\n    # Print performance metrics.\n    print('Test Loss: {:.4f}, Test Acc: {:.4f}'.format(test_loss, test_acc))\n    \n    return test_loss, test_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Delete variables to reduce space","metadata":{}},{"cell_type":"markdown","source":"# Function to test both models combined","metadata":{}},{"cell_type":"code","source":"def test_models(images, labels_has_pneumonia, labels_type_of_pneumonia, model_detect_pneumonia, model_type_pneumonia):\n\n    test_corrects = 0\n    test_total = 0\n    for i in range(len(images)):\n        test_total += 1\n        \n        # Pass image through the first network\n        model_detect_pneumonia.eval() # Set network to evaluation mode\n        with torch.no_grad():\n            output1 = model_detect_pneumonia(images[i].unsqueeze(0).to(device))\n        \n        # Check if model predicted correctly\n        _, pred1 = torch.max(output1, 1)\n        if pred1.item() != labels_has_pneumonia[i]: # If predicted wrongly\n            continue\n        elif pred1.item() == 0: # If predicted correct and it is not pneumonia\n            test_corrects += 1\n            continue\n            \n        # it will continue if predicted correct and pneumonia is predicted\n\n        # Pass image through the second network\n        model_type_pneumonia.eval() # Set network to evaluation mode\n        with torch.no_grad():\n            output2 = model_type_pneumonia(images[i].unsqueeze(0).to(device))\n\n        # Check if the second network predicts correcty\n        _, pred2 = torch.max(output2, 1)\n        if pred2.item() != labels_type_of_pneumonia[i]: # If predicted wrongly\n            continue\n            \n        # Predictions went well!\n        test_corrects += 1\n        \n    # Calculate validation loss and accuracy.\n    #test_loss = val_loss_sum / val_total\n    test_acc = float(test_corrects) / test_total\n\n    # Print epoch and accuracy\n    print('Test Accuracy: {:.4}'.format(test_acc))\n     \n    return test_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get the test data and process it","metadata":{}},{"cell_type":"code","source":"# GET TEST DATA\n\ntest_normal_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/test/NORMAL/'\ntest_pneumonia_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA/'\n\ntest_images = []\ntest_labels_has_pn = []\ntest_labels_type_pn = []\n\ntest_images_pn = []\n\n# LOAD PNUMONIA DATASET AND SAVE LABELS\n\nfor filename in os.listdir(test_pneumonia_path):\n    splited = filename.split('_')\n    if splited[1] == \"virus\":\n        img = Image.open(os.path.join(test_pneumonia_path, filename))\n        test_images.append(img)\n        test_images_pn.append(img)\n        test_labels_has_pn.append(1)\n        test_labels_type_pn.append(0)\n    elif splited[1] == \"bacteria\":\n        img = Image.open(os.path.join(test_pneumonia_path, filename))\n        test_images.append(img)\n        test_images_pn.append(img)\n        test_labels_has_pn.append(1)\n        test_labels_type_pn.append(1)\n\n# LOAD NORMAL DATASET AND LABELS\nfor filename in os.listdir(test_normal_path):\n    if filename.endswith(\".jpeg\"):\n        img = Image.open(os.path.join(test_normal_path, filename))\n        test_images.append(img)\n        test_labels_has_pn.append(0)       \n        \n# apply the transforms to each image in the list\ntest_images_transformed = []\nfor i in range(len(test_images_pn)):\n    test_images_transformed.append(transform(test_images_pn[i]))\ntest_images_pn = test_images_transformed\n\ntest_images_pn_transformed = []\nfor i in range(len(test_images)):\n    test_images_pn_transformed.append(transform(test_images[i]))\ntest_images = test_images_pn_transformed\n\nprint(\"test_image size: \", len(test_images))\nprint(\"test_labels_has_pn size: \", len(test_labels_has_pn))\nprint(\"test_labels_type_pn size: \", len(test_labels_type_pn))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test each model seperately","metadata":{}},{"cell_type":"code","source":"# Create a PyTorch DataLoader for the training and validation sets\ntest_has_pneumonia_dataset = torch.utils.data.TensorDataset(torch.stack(test_images), torch.tensor(test_labels_has_pn))\ntest_has_pneumonia_loader = torch.utils.data.DataLoader(test_has_pneumonia_dataset, batch_size=50, shuffle=False)\ntest_model(model_detect_pneumonia, test_has_pneumonia_loader, criterion)\n\ndel test_has_pneumonia_dataset\ndel test_has_pneumonia_loader\n\ntest_type_pneumonia_dataset = torch.utils.data.TensorDataset(torch.stack(test_images_pn), torch.tensor(test_labels_type_pn))\ntest_type_pneumonia_loader = torch.utils.data.DataLoader(test_type_pneumonia_dataset, batch_size=50, shuffle=False)\ntest_model(model_detect_type_pneumonia, test_type_pneumonia_loader, criterion)\n\ndel test_type_pneumonia_dataset\ndel test_type_pneumonia_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test both models combined","metadata":{}},{"cell_type":"code","source":"# TEST THE MODELS\n\ntest_models(test_images, test_labels_has_pn, test_labels_type_pn, model_detect_pneumonia, model_detect_type_pneumonia)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}